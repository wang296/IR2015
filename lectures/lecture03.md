---
layout: default
title: Natural Language Processing
---

## Announcements
- 34 students enrolled in Piazza. Getting there...
- mp1 released on Friday (6/6), due in one week. **This is an individual
  assignment!**
- Project proposals due on 6/13. We just need a proposal -- you are allowed to
  change your mind, but we want you thinking about forming groups and picking a
  task. Please meet with Hongning or me to talk about a project idea if you're
  unsure
- Reminder: Hongning's office hours Monday at 9am

## Review
- Pull vs Push
- Querying vs Browsing
- Text retrieval vs text mining
- NLP in TIS

## Lecture plan
- What actually is NLP?
- NLP pipeline
- Examples of NLP
- Challenges in NLP / how much do we really need?
- NLP for TIS
- Statistical language models

## Links
- [NLP in the
  movies](http://web.science.mq.edu.au/~rdale/resources/nlpinthemovies/)
- IBM's [Watson](http://www.ibm.com/smarterplanet/us/en/ibmwatson/)
- Machine translation (google translate, FB's bing translate)
- Dialog systems [IKEA help
  center](http://www.ikea.com/ms/en_US/customer_service/splash.html) or
  [cleverbot](http://www.cleverbot.com/)
- Sentiment/opinion analysis

## What is NLP (NLP subfields)
- Morphology
- Syntax
- Semantics
- Pragmatics
- Discourse
- Inference

## The NLP pipeline (NLP technologies)
- Tokenizer/segmenter (identify words and sentences)
- Morphological analyzer/POS tagger (find POS and structure of words)
- Word sense disambiguation (find meaning of words)
- Syntactic/semantic parser (find structure to sentences)
- Coreference resolution/discourse model (keep track of entities and events
  mentioned)

## Examples of NLP
- Draw analysis of *"A dog is chasing a boy on the playground"*
- [Stanford sentiment
  analysis](http://nlp.stanford.edu:8080/sentiment/rntnDemo.html)
- [Stanford parser](http://nlp.stanford.edu:8080/parser/)
- [Stanford CoreNLP demo](http://nlp.stanford.edu:8080/corenlp/)
- [Illinois tools](http://cogcomp.cs.illinois.edu/page/demos)
- Use these for your projects!

## Examples of challenges
- Ambiguity is the main issue
- human agreement on POS tagging is 97%. Chunking is 95%. Note that chunking
  usually depends on POS output...
- Robust and general NLP tends to be shallow, while deep understanding doesn't
  scale up or is focused on a specific domain

## How much NLP is really needed?
- Dependency on NLP (low to high): QA, translation, topic mining,
  summarization, extraction, retrieval, classification
- Bad NLP means bad TIS?
- Nowadays, mostly statistical NLP ("data-driven")
- For example, statistical language models
- Simple models are preferred (e.g. unigram LMs, aka "bag-of-words")

## What is a statistical LM?
- A probability distribution over word sequences
- Can also be thought of as a mechanism for generating text
- [Funny example](http://kingjamesprogramming.tumblr.com/)

## Unigram LM
- Idea: generate a piece of text by generating each word individually. If
  $\theta$ is our distribution over words (a multinomial), and $D$ is our
  document, then

  $$p(D|\theta) = \prod\_{i=1}^{|D|}p(D\_i|\theta)$$

  where $p(D_i|\theta)$ is an individual word's probability in the LM

- Estimation of a LM with maximum likelihood
- Assumption: words generated independently and each document is only generated
  from a single topic
- MLE = maximum likelihood estimation = simply counting! If you have a bunch of
  documents, count the occurrence of each word divided by the total number of
  words
- You can use MLE to estimate $\theta$ given a collection of documents all
  about the same topic
- Say we have two topic LMs, $\theta\_1$ and $\theta\_2$. We know our document
  $D$ was generated by one of them. How do we find the more likely $\theta$
  that generated the document?

## What you should know
- NLP is the foundation of TIS
- Better NLP is necessary for sophisticated tasks
- But, shallow NLP doesn't necessarily mean bad TIS
- Most effective NLP techniques are often statistical
- What is a unigram (bag-of-words) language model?
- How do you generate a document with a LM?
- How do you estimate a LM?

## Next time
- Information retrieval in one lecture
- What is the outline of topics in Part II of the class?
